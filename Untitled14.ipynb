{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179ebe4e-c959-4207-9060-c8bc96b19b5b",
   "metadata": {},
   "source": [
    "# 1.SKU Rationalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8c084-dbc4-4d0d-934f-6b2a81d29371",
   "metadata": {},
   "source": [
    "To identify fast-moving and slow-moving SKUs, we need to establish velocity thresholds for all SKUs in our inventory.\n",
    "To achieve a rationalized SKU assortment, we must understand which products contribute most significantly to total revenue. This can be accomplished through ABC Analysis, which classifies inventory based on revenue contribution and helps prioritize SKUs accordingly.\n",
    "This combined approach of velocity analysis and ABC classification enables data-driven decisions for optimizing our product assortment.\n",
    "The below code justify the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc53d97-ac37-4b92-8fbc-afcf9e5c69c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "#Data Loading\n",
    "sales =pd.read_csv('sales.csv')\n",
    "sales.columns = [c.strip() for c in sales.columns]\n",
    "\n",
    "#Formatting the Date column\n",
    "sales['date']=pd.to_datetime(sales['date'],format='%d-%m-%Y')\n",
    "sales['line_renvenue']= sales['sku_price']*sales['sku_units']\n",
    "sales.head()\n",
    "\n",
    "#Finding the min max date for ABC Testing\n",
    "min_day=sales['date'].min()\n",
    "max_day=sales['date'].max()\n",
    "days=(max_day-min_day).days+1\n",
    "days\n",
    "\n",
    "#Aggerating for getting the first and last sales date\n",
    "agg = sales.groupby(['sku_id','sku_name','category']).agg(\n",
    "    total_units_sold=('sku_units','sum'),\n",
    "    total_revenue=('line_renvenue','sum'),\n",
    "    first_sale=('date','min'),\n",
    "    last_sale=('date','max'),\n",
    "    n_orders=('order_id','nunique')\n",
    ").reset_index()\n",
    "agg.head()\n",
    "\n",
    "#Calculating the per day revenue \n",
    "agg['unit_per_day_global']=agg['total_revenue']/days\n",
    "#Calculation per day sales for all the active days\n",
    "agg['active_days']=(agg['last_sale'] - agg['first_sale']).dt.days + 1\n",
    "agg['units_per_day_active'] = agg['total_units_sold'] / agg['active_days']\n",
    "agg = agg.sort_values('total_revenue',ascending = False)\n",
    "total_rev = agg['total_revenue'].sum()\n",
    "agg['cum_revenue'] = agg['total_revenue'].cumsum()\n",
    "agg['cum_revenue_pct']=agg['cum_revenue']/total_rev\n",
    "def abc(p):\n",
    "    if p <= 0.70:\n",
    "        return 'A'\n",
    "    elif p <= 0.90:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "\n",
    "\n",
    "agg['abc_class'] = agg['cum_revenue_pct'].apply(abc)\n",
    "\n",
    "agg.head()\n",
    "# Velocity Analysis\n",
    "velocity = agg['unit_per_day_global'].median()\n",
    "agg['keep'] = False\n",
    "agg['keep_reason'] = ''\n",
    "\n",
    "#  A-class SKUs == (top revenue drivers)\n",
    "agg.loc[agg['abc_class'] == 'A', 'keep'] = True\n",
    "agg.loc[agg['abc_class'] == 'A', 'keep_reason'] = 'ABC-A top revenue'\n",
    "\n",
    "# Keep B-class SKUs only if velocity is above threshold\n",
    "mask_B = (agg['abc_class'] == 'B') & (agg['unit_per_day_global'] >= velocity)\n",
    "agg.loc[mask_B, 'keep'] = True\n",
    "agg.loc[mask_B, 'keep_reason'] = 'ABC-B & velocity high'\n",
    "\n",
    "# Keep All pharmacy SKUs (business rule: always keep)\n",
    "pharmacy_skus = sales[sales['is_pharmacy'] == True]['sku_id'].unique()\n",
    "mask_pharmacy = agg['sku_id'].isin(pharmacy_skus)\n",
    "agg.loc[mask_pharmacy, 'keep'] = True\n",
    "agg.loc[mask_pharmacy, 'keep_reason'] = 'Pharmacy - always keep'\n",
    "\n",
    "# Final List guyssss\n",
    "agg.head(20)\n",
    "agg.to_csv('ABC.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a1036-ae62-42ae-8c30-7be6461efc4d",
   "metadata": {},
   "source": [
    "# 2.Daily Replenishment Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbdc05c-4f92-4b68-b911-cbe1535316c0",
   "metadata": {},
   "source": [
    "To generate a stable and reliable daily forecast for each SKU, we calculate both a recent 30-day average and a global historical average. The recent window reflects the most current buying pattern, and SKUs with no sales in the last 30 days naturally get a recent average of 0. The global average ensures slow-moving or intermittent SKUs do not get under-forecasted. Finally, we pick the better signal: use recent average when recent demand is strong, otherwise fallback to global average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccbd27c-4cd6-467f-b9b1-27ac79752643",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.rename(columns={'darkstore/warehouse':'darkstore_id'}, inplace=True)\n",
    "\n",
    "# Creating Window of 30 days\n",
    "max_date = sales['date'].max()\n",
    "recent_start = max_date - pd.Timedelta(days=29)\n",
    "recent = sales[sales['date'] >= recent_start]\n",
    "\n",
    "# Getting the past 30 days record \n",
    "recent_forecast = (\n",
    "    recent.groupby(['darkstore_id','sku_id'])['sku_units']\n",
    "    .sum()\n",
    "    .div(30)                             \n",
    "    .reset_index()\n",
    "    .rename(columns={'sku_units':'recent_avg'})\n",
    ")\n",
    "\n",
    "# Calculating the global forcast\n",
    "days_total = (max_date - sales['date'].min()).days + 1\n",
    "\n",
    "global_forecast = (\n",
    "    sales.groupby(['darkstore_id','sku_id'])['sku_units']\n",
    "    .sum()\n",
    "    .div(days_total)                     \n",
    "    .reset_index()\n",
    "    .rename(columns={'sku_units':'global_avg'})\n",
    ")\n",
    "\n",
    "# Merging the both forecast \n",
    "df = recent_forecast.merge(global_forecast,\n",
    "                           on=['darkstore_id','sku_id'],\n",
    "                           how='outer')\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Picking up the best\n",
    "def pick(row):\n",
    "    if row['recent_avg'] >= 3:    # if SKU had good recent movement\n",
    "        return row['recent_avg']\n",
    "    else:\n",
    "        return row['global_avg']  # fallback to global average\n",
    "\n",
    "df['forecast'] = df.apply(pick, axis=1)\n",
    "\n",
    "# Round up demand for safety\n",
    "df['forecast'] = np.ceil(df['forecast']).astype(int)\n",
    "df.to_csv('Forecast_Plan.csv', index=False)\n",
    "df.head()\n",
    "\n",
    "# Loading the Data \n",
    "inventory = pd.read_csv('Inventory.csv')\n",
    "inventory.columns = [c.strip() for c in inventory.columns]\n",
    "inventory.rename(columns={\n",
    "    'Item Code':'sku_id',\n",
    "    'Available Qty':'mother_available',\n",
    "    'Mother Warehouse':'darkstore_id'\n",
    "}, inplace=True)\n",
    "inventory['sku_id'] = inventory['sku_id'].astype(str)\n",
    "inventory['mother_available'] = inventory['mother_available'].astype(int)\n",
    "\n",
    "#Getting the total mother stock\n",
    "mother_stock = inventory.groupby('sku_id')['mother_available'].sum().reset_index()\n",
    "\n",
    "#Loading the Transit Data\n",
    "in_transit = pd.read_csv('In-Transit.csv')\n",
    "in_transit.columns = [c.strip() for c in in_transit.columns]\n",
    "\n",
    "# Melt pivoted file\n",
    "in_transit_long = in_transit.melt(\n",
    "    id_vars=['SKU'],\n",
    "    var_name='darkstore_id',\n",
    "    value_name='qty_in_transit'\n",
    ")\n",
    "\n",
    "in_transit_long.rename(columns={'SKU':'sku_id'}, inplace=True)\n",
    "in_transit_long['sku_id'] = in_transit_long['sku_id'].astype(str)\n",
    "in_transit_long['qty_in_transit'] = in_transit_long['qty_in_transit'].fillna(0).astype(int)\n",
    "\n",
    "# keep only positive\n",
    "in_transit_long = in_transit_long[in_transit_long['qty_in_transit'] > 0]\n",
    "\n",
    "\n",
    "df['sku_id'] = df['sku_id'].astype(str)\n",
    "\n",
    "# CLEAN old in-transit columns from df (critical fix)\n",
    "for col in ['qty_in_transit','qty_in_transit_x','qty_in_transit_y']:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# merge\n",
    "df = df.merge(in_transit_long, on=['darkstore_id','sku_id'], how='left')\n",
    "df['qty_in_transit'] = df['qty_in_transit'].fillna(0)\n",
    "\n",
    "# no darkstore inventory file → assume 0\n",
    "df['available_qty'] = 0\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5 — CALCULATE RAW NEEDED (before constraints)\n",
    "# ============================================================\n",
    "\n",
    "df['needed'] = df['forecast'] - (df['available_qty'] + df['qty_in_transit'])\n",
    "df['needed'] = df['needed'].clip(lower=0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6 — APPLY DARKSTORE 5000-UNIT CAPACITY RULE\n",
    "# ============================================================\n",
    "\n",
    "# total current stock at darkstore = available (0) + in-transit\n",
    "df['current_total'] = df['available_qty'] + df['qty_in_transit']\n",
    "\n",
    "# max they can still take\n",
    "df['cap_limit'] = 5000 - df['current_total']\n",
    "df['cap_limit'] = df['cap_limit'].clip(lower=0)\n",
    "\n",
    "# final after capacity\n",
    "df['after_capacity'] = df[['needed','cap_limit']].min(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 7 — APPLY MOTHER WAREHOUSE STOCK LIMIT\n",
    "# ============================================================\n",
    "\n",
    "final_alloc = []\n",
    "\n",
    "for sku in df['sku_id'].unique():\n",
    "\n",
    "    sku_df = df[df['sku_id'] == sku].copy()\n",
    "    total_req = sku_df['after_capacity'].sum()\n",
    "\n",
    "    mother_qty = mother_stock[mother_stock['sku_id'] == sku]['mother_available'].sum()\n",
    "\n",
    "    if mother_qty >= total_req:\n",
    "        # full allocation\n",
    "        for _, r in sku_df.iterrows():\n",
    "            final_alloc.append([r['darkstore_id'], sku, int(r['after_capacity'])])\n",
    "\n",
    "    else:\n",
    "        # proportional allocation\n",
    "        if total_req == 0:\n",
    "            continue\n",
    "\n",
    "        sku_df['prop'] = sku_df['after_capacity'] / total_req\n",
    "        sku_df['raw_alloc'] = sku_df['prop'] * mother_qty\n",
    "\n",
    "        # floor allocation\n",
    "        sku_df['alloc'] = np.floor(sku_df['raw_alloc']).astype(int)\n",
    "\n",
    "        # distribute remaining units by fractional part\n",
    "        remaining = mother_qty - sku_df['alloc'].sum()\n",
    "\n",
    "        sku_df['fraction'] = sku_df['raw_alloc'] - sku_df['alloc']\n",
    "        sku_df = sku_df.sort_values('fraction', ascending=False)\n",
    "\n",
    "        for i in range(int(remaining)):\n",
    "            sku_df.iloc[i, sku_df.columns.get_loc('alloc')] += 1\n",
    "\n",
    "        for _, r in sku_df.iterrows():\n",
    "            final_alloc.append([r['darkstore_id'], sku, int(r['alloc'])])\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 8 — CREATE FINAL REPLENISHMENT PLAN CSV\n",
    "# ============================================================\n",
    "\n",
    "final_df = pd.DataFrame(final_alloc, columns=['Darkstore_ID','SKU','Total_Replenish_Quantity'])\n",
    "final_df = final_df[final_df['Total_Replenish_Quantity'] > 0]\n",
    "\n",
    "final_df.to_csv('Replenishment_Plan.csv', index=False)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218839ec-65a2-4862-8f92-2a741af1001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>DKS_Blr_BGRoad_001</th>\n",
       "      <th>DKS_Blr_btmlayout_001</th>\n",
       "      <th>DKS_Blr_HSRlayout_001</th>\n",
       "      <th>DKS_Blr_kaggdaspura_001</th>\n",
       "      <th>DKS_Blr_kalyannagar_001</th>\n",
       "      <th>DKS_Blr_Marathahalli_001</th>\n",
       "      <th>DKS_Blr_Sheshadripurm_001</th>\n",
       "      <th>DKS_Blr_varthur_001</th>\n",
       "      <th>DKS_Blr_whitefield_001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLILI0001SPY</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFOWF0053SH</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFOWF0069SH</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFOWF0056SH</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFOWF0132WH</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SKU  DKS_Blr_BGRoad_001  DKS_Blr_btmlayout_001  \\\n",
       "0  CLILI0001SPY                  21                     20   \n",
       "1   CFOWF0053SH                   9                      5   \n",
       "2   CFOWF0069SH                  15                      1   \n",
       "3   CFOWF0056SH                  22                     10   \n",
       "4   CFOWF0132WH                  20                      8   \n",
       "\n",
       "   DKS_Blr_HSRlayout_001  DKS_Blr_kaggdaspura_001  DKS_Blr_kalyannagar_001  \\\n",
       "0                     18                       20                       13   \n",
       "1                     10                       18                       28   \n",
       "2                     31                       35                       22   \n",
       "3                     27                       22                       29   \n",
       "4                     13                       18                       18   \n",
       "\n",
       "   DKS_Blr_Marathahalli_001  DKS_Blr_Sheshadripurm_001  DKS_Blr_varthur_001  \\\n",
       "0                         2                          6                   12   \n",
       "1                         4                          4                    0   \n",
       "2                        13                          3                    4   \n",
       "3                        13                          0                    0   \n",
       "4                         1                          3                   10   \n",
       "\n",
       "   DKS_Blr_whitefield_001  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_transit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe8588e4-0db6-4cde-b983-f4cbce444279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Darkstore_ID</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Total_Replenish_Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18232</th>\n",
       "      <td>MWH_Ggn_bhajgera_001</td>\n",
       "      <td>UNIBAN0001</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18233</th>\n",
       "      <td>MWH_Mum_Bhiwandi_001</td>\n",
       "      <td>UNIBAN0001</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>MWH_Mum_Bhiwandi_001</td>\n",
       "      <td>CFOWF0132WH</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>MWH_Ggn_bhajgera_001</td>\n",
       "      <td>CFOWF0132WH</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18231</th>\n",
       "      <td>MWH_Blr_Neelmangla_001</td>\n",
       "      <td>UNIBAN0001</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Darkstore_ID          SKU  Total_Replenish_Quantity\n",
       "18232    MWH_Ggn_bhajgera_001   UNIBAN0001                       107\n",
       "18233    MWH_Mum_Bhiwandi_001   UNIBAN0001                        55\n",
       "4124     MWH_Mum_Bhiwandi_001  CFOWF0132WH                        49\n",
       "4123     MWH_Ggn_bhajgera_001  CFOWF0132WH                        41\n",
       "18231  MWH_Blr_Neelmangla_001   UNIBAN0001                        37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_sorted = final_df.sort_values(by='Total_Replenish_Quantity', ascending=False)\n",
    "final_df_sorted.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a574c73-34e0-41fa-9d26-7d860fd37ecc",
   "metadata": {},
   "source": [
    "# 3. Mother Warehouse Picklist Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078b0b8e-21d7-42c5-9232-90f6b7f32db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shelf_Location</th>\n",
       "      <th>Batch_ID</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Quantity_to_Pick</th>\n",
       "      <th>Destination_Darkstore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15703</th>\n",
       "      <td>HDR10-1-A</td>\n",
       "      <td>34D5102</td>\n",
       "      <td>DTRBC00012DC</td>\n",
       "      <td>1</td>\n",
       "      <td>DKS_Blr_btmlayout_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15704</th>\n",
       "      <td>HDR10-1-A</td>\n",
       "      <td>34D5102</td>\n",
       "      <td>DTRBC00012DC</td>\n",
       "      <td>1</td>\n",
       "      <td>MWH_Blr_Neelmangla_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15705</th>\n",
       "      <td>HDR10-1-A</td>\n",
       "      <td>34D5102</td>\n",
       "      <td>DTRBC00012DC</td>\n",
       "      <td>1</td>\n",
       "      <td>MWH_Ggn_bhajgera_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12235</th>\n",
       "      <td>HDR10-1-B</td>\n",
       "      <td>5459739</td>\n",
       "      <td>DFODF0016HN</td>\n",
       "      <td>1</td>\n",
       "      <td>DKS_Blr_HSRlayout_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12236</th>\n",
       "      <td>HDR10-1-B</td>\n",
       "      <td>5459739</td>\n",
       "      <td>DFODF0016HN</td>\n",
       "      <td>1</td>\n",
       "      <td>DKS_Blr_Marathahalli_001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Shelf_Location Batch_ID           SKU  Quantity_to_Pick  \\\n",
       "15703      HDR10-1-A  34D5102  DTRBC00012DC                 1   \n",
       "15704      HDR10-1-A  34D5102  DTRBC00012DC                 1   \n",
       "15705      HDR10-1-A  34D5102  DTRBC00012DC                 1   \n",
       "12235      HDR10-1-B  5459739   DFODF0016HN                 1   \n",
       "12236      HDR10-1-B  5459739   DFODF0016HN                 1   \n",
       "\n",
       "          Destination_Darkstore  \n",
       "15703     DKS_Blr_btmlayout_001  \n",
       "15704    MWH_Blr_Neelmangla_001  \n",
       "15705      MWH_Ggn_bhajgera_001  \n",
       "12235     DKS_Blr_HSRlayout_001  \n",
       "12236  DKS_Blr_Marathahalli_001  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===========================================\n",
    "# STEP A — LOAD REPLENISHMENT PLAN\n",
    "# ===========================================\n",
    "\n",
    "repl = final_df.copy()\n",
    "repl['SKU'] = repl['SKU'].astype(str)\n",
    "\n",
    "# ===========================================\n",
    "# STEP B — LOAD MOTHER WAREHOUSE INVENTORY\n",
    "# ===========================================\n",
    "\n",
    "mw = pd.read_csv('Inventory.csv')\n",
    "mw.columns = [c.strip() for c in mw.columns]\n",
    "\n",
    "mw.rename(columns={\n",
    "    'Item Code':'sku_id',\n",
    "    'Available Qty':'mother_available',\n",
    "    'Mother Warehouse':'warehouse_id',\n",
    "    'Shelf':'shelf_location',\n",
    "    'Batch No':'batch_id'\n",
    "}, inplace=True)\n",
    "\n",
    "mw['sku_id'] = mw['sku_id'].astype(str)\n",
    "mw['mother_available'] = mw['mother_available'].astype(int)\n",
    "\n",
    "# Filter only MWH_Blr_Neelmangla_001\n",
    "mw = mw[mw['warehouse_id'] == 'MWH_Blr_Neelmangla_001']\n",
    "\n",
    "# Sort FIFO: by SKU → by oldest batch → by shelf\n",
    "mw = mw.sort_values(by=['sku_id','batch_id'], ascending=[True,True])\n",
    "\n",
    "# ===========================================\n",
    "# STEP C — BUILD PICKLIST USING FIFO\n",
    "# ===========================================\n",
    "\n",
    "picklist_rows = []\n",
    "\n",
    "for i, row in repl.iterrows():\n",
    "    sku = row['SKU']\n",
    "    qty_needed = row['Total_Replenish_Quantity']\n",
    "    dest = row['Darkstore_ID']\n",
    "    \n",
    "    # Get all batches for this SKU\n",
    "    sku_batches = mw[mw['sku_id'] == sku].copy()\n",
    "    \n",
    "    for j, b in sku_batches.iterrows():\n",
    "        if qty_needed == 0:\n",
    "            break\n",
    "        \n",
    "        available = b['mother_available']\n",
    "        take = min(available, qty_needed)\n",
    "        \n",
    "        if take > 0:\n",
    "            picklist_rows.append([\n",
    "                b['shelf_location'],\n",
    "                b['batch_id'],\n",
    "                sku,\n",
    "                take,\n",
    "                dest\n",
    "            ])\n",
    "            \n",
    "            # reduce available qty in that batch\n",
    "            mw.loc[j, 'mother_available'] -= take\n",
    "            qty_needed -= take\n",
    "\n",
    "# ===========================================\n",
    "# STEP D — CREATE PICKLIST DATAFRAME\n",
    "# ===========================================\n",
    "\n",
    "picklist = pd.DataFrame(picklist_rows, \n",
    "    columns=['Shelf_Location','Batch_ID','SKU','Quantity_to_Pick','Destination_Darkstore']\n",
    ")\n",
    "\n",
    "# Sort final picklist by shelf then batch\n",
    "picklist = picklist.sort_values(by=['Shelf_Location','Batch_ID'])\n",
    "\n",
    "# Save file\n",
    "picklist.to_csv('Master_Picklist.csv', index=False)\n",
    "\n",
    "picklist.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f31969-a0b4-4c8c-8d1e-c3f41a19ac0d",
   "metadata": {},
   "source": [
    "# 4.Performance Measurement & Inventory Health Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4e8b3-04d3-412d-a23c-0ca264f0dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 0) PREP — ABC map + SKU universe\n",
    "# ============================================================\n",
    "\n",
    "# Map SKUs → ABC class\n",
    "if \"agg\" in globals() and \"abc_class\" in agg.columns:\n",
    "    abc_map = agg.set_index(agg[\"sku_id\"].astype(str))[\"abc_class\"].to_dict()\n",
    "elif \"keep_list\" in globals() and \"abc_class\" in keep_list.columns:\n",
    "    abc_map = keep_list.set_index(keep_list[\"sku_id\"].astype(str))[\"abc_class\"].to_dict()\n",
    "else:\n",
    "    abc_map = {}\n",
    "\n",
    "# SKU Universe\n",
    "if \"keep_list\" in globals():\n",
    "    sku_universe = keep_list[\"sku_id\"].astype(str).unique().tolist()\n",
    "else:\n",
    "    sku_universe = df[\"sku_id\"].astype(str).unique().tolist()\n",
    "\n",
    "# Fix forecast df\n",
    "forecast = df.copy()\n",
    "forecast[\"sku_id\"] = forecast[\"sku_id\"].astype(str)\n",
    "forecast[\"darkstore_id\"] = forecast[\"darkstore_id\"].astype(str)\n",
    "\n",
    "# ============================================================\n",
    "# 1) LOAD MOTHER WAREHOUSE INVENTORY\n",
    "# ============================================================\n",
    "\n",
    "inv = inventory.copy()\n",
    "inv.rename(columns={\n",
    "    \"Item Code\": \"sku_id\",\n",
    "    \"Available Qty\": \"mother_available\",\n",
    "    \"Mother Warehouse\": \"warehouse_name\",\n",
    "    \"Shelf\": \"shelf_location\",\n",
    "    \"Batch No\": \"batch_id\"\n",
    "}, inplace=True)\n",
    "\n",
    "inv[\"sku_id\"] = inv[\"sku_id\"].astype(str)\n",
    "inv[\"mother_available\"] = inv[\"mother_available\"].astype(int)\n",
    "\n",
    "# Only MWH_Blr_Neelmangla_001 exists → treat all rows as that WH\n",
    "inv[\"warehouse_id\"] = \"MWH_Blr_Neelmangla_001\"\n",
    "\n",
    "mother_inv = inv.copy()\n",
    "\n",
    "mother_stock = (\n",
    "    mother_inv.groupby(\"sku_id\")[\"mother_available\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sku_id\": \"SKU\"})\n",
    ")\n",
    "mother_stock[\"SKU\"] = mother_stock[\"SKU\"].astype(str)\n",
    "mother_map = mother_stock.set_index(\"SKU\")[\"mother_available\"].to_dict()\n",
    "\n",
    "# ============================================================\n",
    "# 2) IN-TRANSIT LONG FORMAT\n",
    "# ============================================================\n",
    "\n",
    "it = in_transit_long.copy()\n",
    "it[\"sku_id\"] = it[\"sku_id\"].astype(str)\n",
    "it[\"darkstore_id\"] = it[\"darkstore_id\"].astype(str)\n",
    "it_map = it.groupby([\"darkstore_id\", \"sku_id\"])[\"qty_in_transit\"].sum().to_dict()\n",
    "\n",
    "# ============================================================\n",
    "# 3) REPLENISHMENT PLAN\n",
    "# ============================================================\n",
    "\n",
    "repl = final_df.copy()\n",
    "repl[\"SKU\"] = repl[\"SKU\"].astype(str)\n",
    "repl[\"Darkstore_ID\"] = repl[\"Darkstore_ID\"].astype(str)\n",
    "\n",
    "repl_map = repl.groupby([\"Darkstore_ID\", \"SKU\"])[\"Total_Replenish_Quantity\"].sum().to_dict()\n",
    "\n",
    "# ============================================================\n",
    "# 4) LOCATION LIST → MWH + All DKS\n",
    "# ============================================================\n",
    "\n",
    "locations = set()\n",
    "locations.add(\"MWH_Blr_Neelmangla_001\")\n",
    "locations.update(forecast[\"darkstore_id\"].unique())\n",
    "locations.update(it[\"darkstore_id\"].unique())\n",
    "locations.update(repl[\"Darkstore_ID\"].unique())\n",
    "locations = sorted(list(locations))\n",
    "\n",
    "# ============================================================\n",
    "# 5) MASTER SKU × LOCATION TABLE\n",
    "# ============================================================\n",
    "\n",
    "rows = []\n",
    "for loc in locations:\n",
    "    for sku in sku_universe:\n",
    "        rows.append({\"location\": loc, \"sku\": sku})\n",
    "univ = pd.DataFrame(rows)\n",
    "\n",
    "# ============================================================\n",
    "# 6) CURRENT ON-HAND STOCK\n",
    "# ============================================================\n",
    "\n",
    "univ[\"current_onhand\"] = 0\n",
    "\n",
    "# Mother WH on-hand\n",
    "univ.loc[univ[\"location\"] == \"MWH_Blr_Neelmangla_001\", \"current_onhand\"] = (\n",
    "    univ.loc[univ[\"location\"] == \"MWH_Blr_Neelmangla_001\", \"sku\"]\n",
    "    .map(lambda x: mother_map.get(x, 0))\n",
    ")\n",
    "\n",
    "# Darkstores have no on-hand file → remain 0\n",
    "\n",
    "# ============================================================\n",
    "# 7) ADD IN-TRANSIT\n",
    "# ============================================================\n",
    "\n",
    "univ[\"in_transit\"] = univ.apply(\n",
    "    lambda r: it_map.get((r[\"location\"], r[\"sku\"]), 0), axis=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 8) ADD REPLENISHMENT (Task 2 output)\n",
    "# ============================================================\n",
    "\n",
    "univ[\"replenishment\"] = univ.apply(\n",
    "    lambda r: repl_map.get((r[\"location\"], r[\"sku\"]), 0), axis=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 9) ADD FORECAST (Daily Sales)\n",
    "# ============================================================\n",
    "\n",
    "fc_map = forecast.set_index([\"darkstore_id\", \"sku_id\"])[\"forecast\"].to_dict()\n",
    "\n",
    "univ[\"forecast_daily\"] = univ.apply(\n",
    "    lambda r: fc_map.get((r[\"location\"], r[\"sku\"]), 0), axis=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 10) OUT OF STOCK (OOS)\n",
    "# ============================================================\n",
    "\n",
    "univ[\"is_oos\"] = univ[\"current_onhand\"] == 0\n",
    "\n",
    "# ============================================================\n",
    "# 11) DAYS OF INVENTORY (DOI)\n",
    "# ============================================================\n",
    "\n",
    "def doi(stock, demand):\n",
    "    if demand <= 0:\n",
    "        return np.nan\n",
    "    return stock / demand\n",
    "\n",
    "univ[\"doi_pre\"] = univ.apply(\n",
    "    lambda r: doi(r[\"current_onhand\"], r[\"forecast_daily\"]), axis=1\n",
    ")\n",
    "\n",
    "univ[\"post_stock\"] = (\n",
    "    univ[\"current_onhand\"] + univ[\"in_transit\"] + univ[\"replenishment\"]\n",
    ")\n",
    "\n",
    "univ[\"doi_post\"] = univ.apply(\n",
    "    lambda r: doi(r[\"post_stock\"], r[\"forecast_daily\"]), axis=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 12) ADD ABC Class\n",
    "# ============================================================\n",
    "\n",
    "univ[\"abc_class\"] = univ[\"sku\"].map(lambda x: abc_map.get(x, \"B\"))\n",
    "\n",
    "# ============================================================\n",
    "# 13) OOS % BY LOCATION × ABC\n",
    "# ============================================================\n",
    "\n",
    "oos_summary = (\n",
    "    univ.groupby([\"location\", \"abc_class\"], as_index=False)\n",
    "    .agg(\n",
    "        num_skus=(\"sku\", \"count\"),\n",
    "        oos_count=(\"is_oos\", \"sum\")\n",
    "    )\n",
    ")\n",
    "oos_summary[\"oos_pct\"] = (oos_summary[\"oos_count\"] / oos_summary[\"num_skus\"]) * 100\n",
    "\n",
    "# ============================================================\n",
    "# 14) DOI SUMMARY BY LOCATION\n",
    "# ============================================================\n",
    "\n",
    "doi_summary = (\n",
    "    univ.groupby(\"location\")\n",
    "    .agg(\n",
    "        total_skus=(\"sku\", \"nunique\"),\n",
    "        median_doi_pre=(\"doi_pre\", lambda x: float(np.nanmedian(x))),\n",
    "        median_doi_post=(\"doi_post\", lambda x: float(np.nanmedian(x))),\n",
    "        mean_doi_pre=(\"doi_pre\", lambda x: float(np.nanmean(x))),\n",
    "        mean_doi_post=(\"doi_post\", lambda x: float(np.nanmean(x))),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "oos_overall = (\n",
    "    univ.groupby(\"location\", as_index=False)\n",
    "    .agg(oos_pct_overall=(\"is_oos\", lambda x: float(x.sum() / len(x) * 100)))\n",
    ")\n",
    "\n",
    "summary = doi_summary.merge(oos_overall, on=\"location\", how=\"left\")\n",
    "\n",
    "# ============================================================\n",
    "# 15) EXPORT FILES\n",
    "# ============================================================\n",
    "\n",
    "oos_summary.to_csv(\"OOS_by_Location_ABC.csv\", index=False)\n",
    "univ.to_csv(\"DOI_by_Location_SKU_detailed.csv\", index=False)\n",
    "summary.to_csv(\"OOS_DOI_Summary.csv\", index=False)\n",
    "\n",
    "# ============================================================\n",
    "# 16) DISPLAY PREVIEW\n",
    "# ============================================================\n",
    "\n",
    "print(\"TASK 4 COMPLETED SUCCESSFULLY ✔\")\n",
    "print(\"Files generated:\")\n",
    "print(\"1. OOS_by_Location_ABC.csv\")\n",
    "print(\"2. DOI_by_Location_SKU_detailed.csv\")\n",
    "print(\"3. OOS_DOI_Summary.csv\\n\")\n",
    "\n",
    "display(summary.head())\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Use existing in-memory variables: oos_summary and summary\n",
    "# If they don't exist this will raise NameError.\n",
    "pivot = oos_summary.pivot_table(index='location', columns='abc_class', values='oos_pct', aggfunc='first').fillna(0)\n",
    "for c in ['A','B','C']:\n",
    "    if c not in pivot.columns:\n",
    "        pivot[c] = 0\n",
    "pivot = pivot[['A','B','C']]\n",
    "locations = pivot.index.tolist()\n",
    "x = np.arange(len(locations))\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "width = 0.25\n",
    "plt.bar(x - width, pivot['A'].values, width=width, label='A')\n",
    "plt.bar(x, pivot['B'].values, width=width, label='B')\n",
    "plt.bar(x + width, pivot['C'].values, width=width, label='C')\n",
    "plt.xticks(x, locations, rotation=45, ha='right')\n",
    "plt.xlabel('Location'); plt.ylabel('OOS % (percent)')\n",
    "plt.title('Out-of-Stock Percentage by Location and ABC Class')\n",
    "plt.legend(title='ABC Class')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "doi_df = summary.set_index('location')[['median_doi_pre','median_doi_post']].fillna(0)\n",
    "locations_doi = doi_df.index.tolist()\n",
    "x2 = np.arange(len(locations_doi))\n",
    "plt.figure(figsize=(14,6))\n",
    "width2 = 0.35\n",
    "plt.bar(x2 - width2/2, doi_df['median_doi_pre'].values, width=width2, label='DOI Pre (median)')\n",
    "plt.bar(x2 + width2/2, doi_df['median_doi_post'].values, width=width2, label='DOI Post (median)')\n",
    "plt.xticks(x2, locations_doi, rotation=45, ha='right')\n",
    "plt.xlabel('Location'); plt.ylabel('Days of Inventory (median)')\n",
    "plt.title('Median Days of Inventory — Pre vs Post Transfer')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d30e5-d901-4682-bc9d-517611299d65",
   "metadata": {},
   "source": [
    "# BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed755e5-4eb9-4221-a661-e530c91a060d",
   "metadata": {},
   "source": [
    "The replenishment process can be significantly improved and automated by building a daily forecasting and allocation engine that pulls sales, inventory, and in-transit data automatically, calculates replenishment needs, and generates picklists without manual effort, supported by real-time inventory updates from all darkstores. To make the plan even more accurate, additional data such as true on-hand stock at each darkstore, lead-time variability, expiry and shelf-life details, promotional or seasonal demand patterns, and cost information would help refine both forecasting and allocation. Beyond this, the company could explore optimizations such as route optimization for delivery vehicles, batch or zone picking inside the warehouse to reduce walking time, dynamic safety-stock policies based on demand variability, and even store-to-store transfers to balance inventory more efficiently across the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11260284-62ca-4e28-b551-96484dddd756",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Inventory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 64\u001b[0m\n\u001b[0;32m     57\u001b[0m mother_map \u001b[38;5;241m=\u001b[39m mother_stock\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSKU\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmother_available\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# 1B) LOAD DARKSTORE ON-HAND INVENTORY\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Assumes a dataframe `darkstore_inventory` already exists\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m dark_inv \u001b[38;5;241m=\u001b[39m \u001b[43mInventory\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     65\u001b[0m dark_inv\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem Code\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msku_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable Qty\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monhand_qty\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDarkstore ID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdarkstore_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m }, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m dark_inv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msku_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dark_inv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msku_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Inventory' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# ============================================================\n",
    "# 0) PREP — ABC map + SKU universe\n",
    "# ============================================================\n",
    "\n",
    "# Map SKUs → ABC class\n",
    "if \"agg\" in globals() and \"abc_class\" in agg.columns:\n",
    "    abc_map = agg.set_index(agg[\"sku_id\"].astype(str))[\"abc_class\"].to_dict()\n",
    "elif \"keep_list\" in globals() and \"abc_class\" in keep_list.columns:\n",
    "    abc_map = keep_list.set_index(keep_list[\"sku_id\"].astype(str))[\"abc_class\"].to_dict()\n",
    "else:\n",
    "    abc_map = {}\n",
    "\n",
    "# SKU Universe\n",
    "if \"keep_list\" in globals():\n",
    "    sku_universe = keep_list[\"sku_id\"].astype(str).unique().tolist()\n",
    "else:\n",
    "    sku_universe = df[\"sku_id\"].astype(str).unique().tolist()\n",
    "\n",
    "# Fix forecast df\n",
    "forecast = df.copy()\n",
    "forecast[\"sku_id\"] = forecast[\"sku_id\"].astype(str)\n",
    "forecast[\"darkstore_id\"] = forecast[\"darkstore_id\"].astype(str)\n",
    "\n",
    "# ============================================================\n",
    "# 1) LOAD MOTHER WAREHOUSE INVENTORY\n",
    "# ============================================================\n",
    "\n",
    "inv = inventory.copy()\n",
    "inv.rename(columns={\n",
    "    \"Item Code\": \"sku_id\",\n",
    "    \"Available Qty\": \"mother_available\",\n",
    "    \"Mother Warehouse\": \"warehouse_name\",\n",
    "    \"Shelf\": \"shelf_location\",\n",
    "    \"Batch No\": \"batch_id\"\n",
    "}, inplace=True)\n",
    "\n",
    "inv[\"sku_id\"] = inv[\"sku_id\"].astype(str)\n",
    "inv[\"mother_available\"] = inv[\"mother_available\"].astype(int)\n",
    "\n",
    "# Only MWH_Blr_Neelmangla_001 exists → treat all rows as that WH\n",
    "inv[\"warehouse_id\"] = \"MWH_Blr_Neelmangla_001\"\n",
    "\n",
    "mother_inv = inv.copy()\n",
    "\n",
    "mother_stock = (\n",
    "    mother_inv.groupby(\"sku_id\")[\"mother_available\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sku_id\": \"SKU\"})\n",
    ")\n",
    "mother_stock[\"SKU\"] = mother_stock[\"SKU\"].astype(str)\n",
    "mother_map = mother_stock.set_index(\"SKU\")[\"mother_available\"].to_dict()\n",
    "\n",
    "# ============================================================\n",
    "# 1B) LOAD DARKSTORE ON-HAND INVENTORY\n",
    "# ============================================================\n",
    "\n",
    "# Assumes a dataframe `darkstore_inventory` already exists\n",
    "dark_inv = Inventory.copy()\n",
    "dark_inv.rename(columns={\n",
    "    \"Item Code\": \"sku_id\",\n",
    "    \"Available Qty\": \"onhand_qty\",\n",
    "    \"Darkstore ID\": \"darkstore_id\"\n",
    "}, inplace=True)\n",
    "\n",
    "dark_inv[\"sku_id\"] = dark_inv[\"sku_id\"].astype(str)\n",
    "dark_inv[\"darkstore_id\"] = dark_inv[\"darkstore_id\"].astype(str)\n",
    "dark_inv[\"onhand_qty\"] = dark_inv[\"onhand_qty\"].astype(int)\n",
    "\n",
    "# Aggregate darkstore stock\n",
    "dark_stock = (\n",
    "    dark_inv.groupby([\"darkstore_id\", \"sku_id\"])[\"onhand_qty\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Build a unified on-hand map for (location, sku)\n",
    "onhand_map = {}\n",
    "\n",
    "# Mother WH\n",
    "for _, row in mother_stock.iterrows():\n",
    "    key = (\"MWH_Blr_Neelmangla_001\", row[\"SKU\"])\n",
    "    onhand_map[key] = onhand_map.get(key, 0) + int(row[\"mother_available\"])\n",
    "\n",
    "# Darkstores\n",
    "for _, row in dark_stock.iterrows():\n",
    "    key = (row[\"darkstore_id\"], row[\"sku_id\"])\n",
    "    onhand_map[key] = onhand_map.get(key, 0) + int(row[\"onhand_qty\"])\n",
    "\n",
    "# ============================================================\n",
    "# 2) IN-TRANSIT LONG FORMAT\n",
    "# ============================================================\n",
    "\n",
    "it = in_transit_long.copy()\n",
    "it[\"sku_id\"] = it[\"sku_id\"].astype(str)\n",
    "it[\"darkstore_id\"] = it[\"darkstore_id\"].astype(str)\n",
    "it_map = it.groupby([\"darkstore_id\", \"sku_id\"])[\"qty_in_transit\"].sum().to_dict()\n",
    "\n",
    "# ============================================================\n",
    "# 3) REPLENISHMENT PLAN\n",
    "# ============================================================\n",
    "\n",
    "repl = final_df.copy()\n",
    "repl[\"SKU\"] = repl[\"SKU\"].astype(str)\n",
    "repl[\"Darkstore_ID\"] = repl[\"Darkstore_ID\"].astype(str)\n",
    "\n",
    "repl_map = repl.groupby([\"Darkstore_ID\", \"SKU\"])[\"Total_Replenish_Quantity\"].sum().to_dict()\n",
    "\n",
    "# ============================================================\n",
    "# 4) LOCATION LIST → MWH + All DKS\n",
    "# ============================================================\n",
    "\n",
    "locations = set()\n",
    "locations.add(\"MWH_Blr_Neelmangla_001\")\n",
    "locations.update(forecast[\"darkstore_id\"].unique())\n",
    "locations.update(it[\"darkstore_id\"].unique())\n",
    "locations.update(repl[\"Darkstore_ID\"].unique())\n",
    "locations.update(dark_inv[\"darkstore_id\"].unique())\n",
    "locations = sorted(list(locations))\n",
    "\n",
    "# ============================================================\n",
    "# 5) MASTER SKU × LOCATION TABLE\n",
    "# ============================================================\n",
    "\n",
    "rows = []\n",
    "for loc in locations:\n",
    "    for sku in sku_universe:\n",
    "        rows.append({\"location\": loc, \"sku\": sku})\n",
    "univ = pd.DataFrame(rows)\n",
    "\n",
    "# ============================================================\n",
    "# 6) CURRENT ON-HAND STOCK (NOW INCLUDING DARKSTORES)\n",
    "# ============================================================\n",
    "\n",
    "univ[\"current_onhand\"] = univ.apply(\n",
    "    lambda r: onhand_map.get((r[\"location\"], r[\"sku\"]), 0),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7) ADD IN-TRANSIT\n",
    "# ============================================================\n",
    "\n",
    "univ[\"in_transit\"] = univ.apply(\n",
    "    lambda r: it_map.get((r[\"location\"], r[\"sku\"]), 0), axis=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 8) ADD REPLENISHMENT (Task 2 output)\n",
    "# ============================================================\n",
    "\n",
    "univ[\"replenishment\"] = univ.apply(\n",
    "    lambda r: repl_map.get((r[\"location\"], r[\"sku\"]), 0), axis=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 9) ADD FORECAST (Daily Sales)\n",
    "# ============================================================\n",
    "\n",
    "fc_map = forecast.set_index([\"darkstore_id\", \"sku_id\"])[\"forecast\"].to_dict()\n",
    "\n",
    "univ[\"forecast_daily\"] = univ.apply(\n",
    "    lambda r: fc_map.get((r[\"location\"], r[\"sku\"]), 0), axis=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 10) OUT OF STOCK (OOS) – PRE TRANSFER\n",
    "# ============================================================\n",
    "\n",
    "univ[\"is_oos\"] = univ[\"current_onhand\"] == 0\n",
    "\n",
    "# ============================================================\n",
    "# 11) DAYS OF INVENTORY (DOI)\n",
    "# ============================================================\n",
    "\n",
    "def doi(stock, demand):\n",
    "    if demand <= 0:\n",
    "        return np.nan\n",
    "    return stock / demand\n",
    "\n",
    "# Pre-transfer DOI\n",
    "univ[\"doi_pre\"] = univ.apply(\n",
    "    lambda r: doi(r[\"current_onhand\"], r[\"forecast_daily\"]), axis=1\n",
    ")\n",
    "\n",
    "# Post-transfer stock and DOI\n",
    "univ[\"post_stock\"] = (\n",
    "    univ[\"current_onhand\"] + univ[\"in_transit\"] + univ[\"replenishment\"]\n",
    ")\n",
    "\n",
    "univ[\"doi_post\"] = univ.apply(\n",
    "    lambda r: doi(r[\"post_stock\"], r[\"forecast_daily\"]), axis=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 12) ADD ABC Class\n",
    "# ============================================================\n",
    "\n",
    "univ[\"abc_class\"] = univ[\"sku\"].map(lambda x: abc_map.get(x, \"B\"))\n",
    "\n",
    "# ============================================================\n",
    "# 13) OOS % BY LOCATION × ABC\n",
    "# ============================================================\n",
    "\n",
    "oos_summary = (\n",
    "    univ.groupby([\"location\", \"abc_class\"], as_index=False)\n",
    "    .agg(\n",
    "        num_skus=(\"sku\", \"count\"),\n",
    "        oos_count=(\"is_oos\", \"sum\")\n",
    "    )\n",
    ")\n",
    "oos_summary[\"oos_pct\"] = (oos_summary[\"oos_count\"] / oos_summary[\"num_skus\"]) * 100\n",
    "\n",
    "# ============================================================\n",
    "# 14) DOI SUMMARY BY LOCATION\n",
    "# ============================================================\n",
    "\n",
    "doi_summary = (\n",
    "    univ.groupby(\"location\")\n",
    "    .agg(\n",
    "        total_skus=(\"sku\", \"nunique\"),\n",
    "        median_doi_pre=(\"doi_pre\", lambda x: float(np.nanmedian(x))),\n",
    "        median_doi_post=(\"doi_post\", lambda x: float(np.nanmedian(x))),\n",
    "        mean_doi_pre=(\"doi_pre\", lambda x: float(np.nanmean(x))),\n",
    "        mean_doi_post=(\"doi_post\", lambda x: float(np.nanmean(x))),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "oos_overall = (\n",
    "    univ.groupby(\"location\", as_index=False)\n",
    "    .agg(oos_pct_overall=(\"is_oos\", lambda x: float(x.sum() / len(x) * 100)))\n",
    ")\n",
    "\n",
    "summary = doi_summary.merge(oos_overall, on=\"location\", how=\"left\")\n",
    "\n",
    "# ============================================================\n",
    "# 15) EXPORT FILES\n",
    "# ============================================================\n",
    "\n",
    "oos_summary.to_csv(\"OOS_by_Location_ABC.csv\", index=False)\n",
    "univ.to_csv(\"DOI_by_Location_SKU_detailed.csv\", index=False)\n",
    "summary.to_csv(\"OOS_DOI_Summary.csv\", index=False)\n",
    "\n",
    "# ============================================================\n",
    "# 16) DISPLAY PREVIEW\n",
    "# ============================================================\n",
    "\n",
    "print(\"TASK 4 COMPLETED SUCCESSFULLY ✔\")\n",
    "print(\"Files generated:\")\n",
    "print(\"1. OOS_by_Location_ABC.csv\")\n",
    "print(\"2. DOI_by_Location_SKU_detailed.csv\")\n",
    "print(\"3. OOS_DOI_Summary.csv\\n\")\n",
    "\n",
    "display(summary.head())\n",
    "\n",
    "# ============================================================\n",
    "# 17) PLOTS\n",
    "# ============================================================\n",
    "\n",
    "# --- OOS by Location & ABC ---\n",
    "pivot = (\n",
    "    oos_summary\n",
    "    .pivot_table(index='location', columns='abc_class', values='oos_pct', aggfunc='first')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "for c in ['A', 'B', 'C']:\n",
    "    if c not in pivot.columns:\n",
    "        pivot[c] = 0\n",
    "\n",
    "pivot = pivot[['A', 'B', 'C']]\n",
    "\n",
    "locations_plot = pivot.index.tolist()\n",
    "x = np.arange(len(locations_plot))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(x - width, pivot['A'].values, width=width, label='A')\n",
    "plt.bar(x,         pivot['B'].values, width=width, label='B')\n",
    "plt.bar(x + width, pivot['C'].values, width=width, label='C')\n",
    "plt.xticks(x, locations_plot, rotation=45, ha='right')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('OOS % (percent)')\n",
    "plt.title('Out-of-Stock Percentage by Location and ABC Class')\n",
    "plt.legend(title='ABC Class')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Median DOI Pre vs Post ---\n",
    "doi_df = summary.set_index('location')[['median_doi_pre', 'median_doi_post']].fillna(0)\n",
    "locations_doi = doi_df.index.tolist()\n",
    "x2 = np.arange(len(locations_doi))\n",
    "width2 = 0.35\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(x2 - width2/2, doi_df['median_doi_pre'].values,  width=width2, label='DOI Pre (median)')\n",
    "plt.bar(x2 + width2/2, doi_df['median_doi_post'].values, width=width2, label='DOI Post (median)')\n",
    "plt.xticks(x2, locations_doi, rotation=45, ha='right')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Days of Inventory (median)')\n",
    "plt.title('Median Days of Inventory — Pre vs Post Transfer')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284093da-54c8-4996-ab12-8997b1d3ca44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
